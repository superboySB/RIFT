policy_name: 'ppo_pluto'
policy_type: 'il'  # CBV action related

obs_type: 'cbv_ppo_pluto_obs'

reward_model: 'dense' # dense or sparse or none

data_keys:
 - CBVs_actions
 - CBVs_actions_old_log_prob
 - CBVs_obs
 - CBVs_next_obs
 - CBVs_reward
 - CBVs_terminated
 - CBVs_done

# buffer related
buffer_capacity: 4096
# training related
save_freq: 50

# rlft config_path
rlft_config_path: 'config'
rlft_config_name: 'ppo_training.yaml'

## unique for pluto model
ckpt_path: 'rift/cbv/planning/model_ckpt/pluto/pluto_1M_aux_cil.ckpt'  # for pretraining
model_path: 'rift/cbv/planning/model_ckpt/ppo_pluto'  # for saving the model
model_type: 'cbv'
use_prediction: False
topk: 10

obs:
  max_agent: 48
  radius: 120  # aligned with the radius in the pluto model
  history_horizon: 2.0
  sample_interval: 0.1

CBV_action_dim: 3  # throttle, steer, brake 

ppo:
  hidden_dim: [256, 256]
  state_dim: 128  # the hidden output state of the pluto model
  action_dim: 3
  clip_epsilon: 0.2
  lambda_entropy: 0.01


